{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN CourseWork - Rajaram Kuberan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/ANN_CourseWork_GoogLeNet_Rajaram_Kuberan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPf6LfXSdxe2"
      },
      "source": [
        "# **7088 CEM - Artificial Neural Network Coursework**\n",
        "##**Coventry University**\n",
        "###**Student Name**: Rajaram Kuberan\n",
        "###**Student ID**  : 10457647\n",
        "###**Email ID**    : kuberanr@coventry.ac.uk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLhhpL_PkRlY"
      },
      "source": [
        "# **Topic: Image Classification of Grocery Items for Ketogenic Shopping Using CNN Architectures**\n",
        "\n",
        "This project Worflow is carried out in five parts:\n",
        "\n",
        "**1. Data Collection**\n",
        "\n",
        "**2. Data Preprocessing**\n",
        "\n",
        "**3. CNN Architecture Selection and Modelling**\n",
        "\n",
        "**4. Image Classification and Prediction**\n",
        "\n",
        "**5. Metrics Calculation**\n",
        "\n",
        "There are two architectures used for this Coursework:\n",
        "\n",
        "1. GoogLeNet Architecture\n",
        "2. Transfer Learning\n",
        "\n",
        "In this Colab Notebook, the first architecture is explained: GoogLeNet Architecture without Transfer Learning and with Transfer Learning. The second  architecture - Transfer Learning using MobileNet architecture is explained in another Colab Notebook - [Link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/Transfer_Learning.ipynb)\n",
        "\n",
        "  GoogLeNet Architecture is used to perform Image Classification on Ketogenic and Non-Ketogenic Food items. The Keras Library is used to build the GoogLeNet CNN architecture. The training/test datas are pushed into the Github repository. \n",
        "\n",
        "Code Link for whole project - [Github link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ.git)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-tqOU9kMEbc"
      },
      "source": [
        "##**1. Data Collection**\n",
        "\n",
        "  The dataset used for this project is not taken directly from Kaggle or UCI data reppsitory. We have novelly scrapped the images from the UK top supermarket webistes, and also added images from two projects where grocery images were used for performing Classification.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnm4HR2SXWNl"
      },
      "source": [
        "###**1.1 Image Scrapping**\n",
        "\n",
        "  Data is collected by scrapping images from websites like [Tesco](https://www.tesco.com/groceries/) and [Morrisons](https://groceries.morrisons.com/browse). Additionally the dataset from [Grocery Dataset](https://github.com/marcusklasson/GroceryStoreDataset/tree/master/dataset) and [Freiburg Grocery Dataset](http://aisdatasets.informatik.uni-freiburg.de/freiburg_groceries_dataset/) are also used. For Image Scrapping, Automation Tool - Selenium written in Java is used in this project. The Selenium with Python was also used. But Java Selenium combination helped us to scrap nearly 1500 images in a single exection of code. In this way, we could scrap nearly 12500+ images from Tesco website and 7500+ images from Morrisons website. The Grocery and Freiburg Dataset contains 5000 images respectively. So, totally we have 30000+ images to perform Classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9eTtOhDXfph"
      },
      "source": [
        "###**1.2 Selenium Java code Link**\n",
        "\n",
        "  Below are the Github link for selenium Java code:\n",
        "\n",
        "Tesco Selenium Java codes - [Link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/Data_Image_Web_scrapping/tesco_selenium.java)\n",
        "\n",
        "Morrisons Selenium Java - [Link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/Data_Image_Web_scrapping/Morrisons_Selenium.java)\n",
        "\n",
        "Dependencies required to execute do Automated Image Scrapping: \n",
        "1. Chromedriver - [Link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/tree/main/Data_Image_Web_scrapping/chromedriver_win32)\n",
        "\n",
        "2. Maven Repository and Selenium Ashot - [Link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/Data_Image_Web_scrapping/selenium_ashot.txt)\n",
        "\n",
        "3. XML Pom file where the dependencies are listed to run the Java Selenium code: [Link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/Data_Image_Web_scrapping/Automation/Images/pom.xml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3yC7iuuMBso"
      },
      "source": [
        "###**1.3 Importing Data from the Github**\n",
        "\n",
        "Git clone is used to import the data from Github to Google Colab. The GPU runtime is used to run the CNN model due to its heavy computational dependencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVzozTnCeSZD",
        "outputId": "a27e1ba0-fa6b-4401-8591-8d8c45e5daff"
      },
      "source": [
        "!git clone https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ANN_Coursework_Coventry_Univ'...\n",
            "remote: Enumerating objects: 4761, done.\u001b[K\n",
            "remote: Counting objects: 100% (4761/4761), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4728/4728), done.\u001b[K\n",
            "remote: Total 30365 (delta 20), reused 4756 (delta 16), pack-reused 25604\u001b[K\n",
            "Receiving objects: 100% (30365/30365), 6.12 GiB | 33.12 MiB/s, done.\n",
            "Resolving deltas: 100% (317/317), done.\n",
            "Checking out files: 100% (31423/31423), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP1wIvcK2lcA"
      },
      "source": [
        "##**2. Data Preprocessing**\n",
        "\n",
        "In this worflow, the dataset of 30000+ images are splitted randomly in the ratio of 80:20.\n",
        "\n",
        "The images are segregated, and stored in separate folders named train and test.\n",
        "\n",
        "Splitting the data code Link: [Python Code](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/splitting_the_data.ipynb)\n",
        "\n",
        "Now ,let's use ImageDataGenerator class to create our train and test dataset and normalize our data. \n",
        "\n",
        "It's important to normalize our data because data going into our CNN to improve its overall performance. We will use the rescale parameter to scale our image pixel values from [0, 255] to [0,1].\n",
        "\n",
        "In each generator, we specify the source directory of our images, the classes, the input image size, the batch size (how many images to process at once), and class mode.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfDDo5X30uDh"
      },
      "source": [
        "###**2.1 Importing the Necessary Libraries**\n",
        "\n",
        "The necessary libraries are imported for performing Data Preprocessing and CNN Modelling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc83Z1_PfQ1B"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from keras.layers import concatenate\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCl02Y24uNCk"
      },
      "source": [
        "###**2.2 Image Preprocessing**\n",
        "\n",
        "In this process, ImageDataGenerator class is used to create our train and test dataset for binary classification.Moreover, data is also normalised.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDF70CK2vhgn"
      },
      "source": [
        "####**2.2.1 Data/Image Normalisation**\n",
        "\n",
        "It's important to normalize our data because most of the CNN architecture accepts images in particular pixel values to improve its overall performance. \n",
        "\n",
        "For this, the rescale parameter is used to scale our image pixel values from [0, 255] to [0,1].\n",
        "\n",
        "In each generator, we specify the source directory of our images, the classes, the input image size, the batch size (how many images to process at once), and class mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2Hg5sXfdcN"
      },
      "source": [
        "# initialising the image size as 224x224\n",
        "IMAGE_SIZE = [224,224]\n",
        "\n",
        "\n",
        "# Setting the Path to test and train data \n",
        "test_path = '/content/ANN_Coursework_Coventry_Univ/test'\n",
        "train_path = '/content/ANN_Coursework_Coventry_Univ/train'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3Jw6oVdfgng"
      },
      "source": [
        "# transforming train data images\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "# transforming train data images\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbWmS9z7dNdJ",
        "outputId": "2a8b8913-73e9-4fc3-d655-3069b04a67a8"
      },
      "source": [
        "#training data \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/ANN_Coursework_Coventry_Univ/train',  # This is the source directory for training images\n",
        "        classes = ['Keto_train', 'Non_Keto_train'],\n",
        "        target_size=(224, 224),  # All images are resized to 224x224\n",
        "        batch_size=32,\n",
        "        # Use binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# testing data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/ANN_Coursework_Coventry_Univ/test',  # This is the source directory for test images\n",
        "        classes = ['Keto_test', 'Non_Keto_Test'],\n",
        "        target_size=(224, 224),  # All images are resized to 224x224\n",
        "        batch_size=16,\n",
        "        # Use binary labels\n",
        "        class_mode='binary')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24861 images belonging to 2 classes.\n",
            "Found 6163 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YFV6A484BT2"
      },
      "source": [
        "##**3. Building the Model**\n",
        "\n",
        "In this project, GoogLeNet Architecture is used to perform Image Classification on Ketogenic and Non-Ketogenic Food items. The Keras Library is used to build the GoogLeNet CNN architecture. The training/test datas are pushed into the Github repository.\n",
        "\n",
        "In GoogLeNet architecture, there ae 4 blocks of Inception layer. Firstly to avoid repeating the layers, create the inception block function so that we can use it in the model easily.\n",
        "\n",
        "Reference: Szegedy, Christian, et al. “Going deeper with convolutions.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.\n",
        "\n",
        "The above 2015 Paper is used as the reference to create the blocks. The kernel size and the convolution layers are \n",
        "exactly written in Python using Keras Library as mentioned in the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qWEOGnhwh06"
      },
      "source": [
        "### **3.1 GoogLeNet Architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtIVSrCq3B7v"
      },
      "source": [
        "####**3.1.1 Create the Inception Blocks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH1JWROnijcp"
      },
      "source": [
        "# create an Inception block \n",
        "def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4): \n",
        "  \n",
        "  # 1st block:\n",
        "  block1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', \n",
        "                 activation = 'relu')(input_layer)\n",
        "\n",
        "  # 2nd block:\n",
        "  block2 = Conv2D(filters = f2_conv1, kernel_size = (1,1), padding = 'same', \n",
        "                 activation = 'relu')(input_layer)\n",
        "  block2 = Conv2D(filters = f2_conv3, kernel_size = (3,3), padding = 'same', \n",
        "                 activation = 'relu')(block2)\n",
        "\n",
        "  # 3rd block:\n",
        "  block3 = Conv2D(filters = f3_conv1, kernel_size = (1,1), padding = 'same', \n",
        "                 activation = 'relu')(input_layer)\n",
        "  block3 = Conv2D(filters = f3_conv5, kernel_size = (5,5), padding = 'same', \n",
        "                 activation = 'relu')(block3)\n",
        "\n",
        "  # 4th block:\n",
        "  block4 = MaxPooling2D((3,3), strides= (1,1), padding = 'same')(input_layer)\n",
        "  block4 = Conv2D(filters = f4, kernel_size = (1,1), padding = 'same', \n",
        "                 activation = 'relu')(block4)\n",
        "\n",
        "  output_layer = concatenate([block1, block2, block3, block4], axis = -1)\n",
        "\n",
        "  return output_layer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR0h0jwR4buV"
      },
      "source": [
        "#### **3.1.2 Create a GoogLenet Layer**\n",
        " Here we will define GoogLeNet Model Layers and then return the model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lFYlnY7ajrG"
      },
      "source": [
        "def GoogLeNet():\n",
        "  # input layer \n",
        "  input_layer = Input(shape = (224, 224, 3))\n",
        "\n",
        "  # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
        "  X = Conv2D(filters = 64, kernel_size = (7,7), strides = 2, padding = 'valid', \n",
        "             activation = 'relu')(input_layer)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
        "\n",
        "  # convolutional layer: filters = 64, strides = 1\n",
        "  X = Conv2D(filters = 64, kernel_size = (1,1), strides = 1, padding = 'same', \n",
        "             activation = 'relu')(X)\n",
        "\n",
        "  # convolutional layer: filters = 192, kernel_size = (3,3)\n",
        "  X = Conv2D(filters = 192, kernel_size = (3,3), padding = 'same', \n",
        "             activation = 'relu')(X)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
        "\n",
        "  # 1st Inception block\n",
        "  X = Inception_block(X, f1 = 64, f2_conv1 = 96, f2_conv3 = 128, f3_conv1 = 16, \n",
        "                      f3_conv5 = 32, f4 = 32)\n",
        "\n",
        "  # 2nd Inception block\n",
        "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 192, f3_conv1 = 32, \n",
        "                      f3_conv5 = 96, f4 = 64)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
        "\n",
        "  # 3rd Inception block\n",
        "  X = Inception_block(X, f1 = 192, f2_conv1 = 96, f2_conv3 = 208, f3_conv1 = 16, \n",
        "                      f3_conv5 = 48, f4 = 64)\n",
        "\n",
        "  # Average Pooling Layer 1:\n",
        "  X1 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
        "  X1 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', \n",
        "              activation = 'relu')(X1)\n",
        "  X1 = Flatten()(X1)\n",
        "  X1 = Dense(1024, activation = 'relu')(X1)\n",
        "  X1 = Dropout(0.7)(X1)\n",
        "  X1 = Dense(5, activation = 'softmax')(X1)\n",
        "\n",
        "  \n",
        "  # 4th Inception block\n",
        "  X = Inception_block(X, f1 = 160, f2_conv1 = 112, f2_conv3 = 224, f3_conv1 = 24, \n",
        "                      f3_conv5 = 64, f4 = 64)\n",
        "\n",
        "  # 5th Inception block\n",
        "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 256, f3_conv1 = 24, \n",
        "                      f3_conv5 = 64, f4 = 64)\n",
        "\n",
        "  # 6th Inception block\n",
        "  X = Inception_block(X, f1 = 112, f2_conv1 = 144, f2_conv3 = 288, f3_conv1 = 32, \n",
        "                      f3_conv5 = 64, f4 = 64)\n",
        "\n",
        "  # Average Pooling Layer 2:\n",
        "  X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
        "  X2 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', \n",
        "              activation = 'relu')(X2)\n",
        "  X2 = Flatten()(X2)\n",
        "  X2 = Dense(1024, activation = 'relu')(X2)\n",
        "  X2 = Dropout(0.7)(X2)\n",
        "  X2 = Dense(1000, activation = 'softmax')(X2)\n",
        "  \n",
        "  \n",
        "  # 7th Inception block\n",
        "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, \n",
        "                      f3_conv5 = 128, f4 = 128)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
        "\n",
        "  # 8th Inception block\n",
        "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, \n",
        "                      f3_conv5 = 128, f4 = 128)\n",
        "\n",
        "  # 9th Inception block\n",
        "  X = Inception_block(X, f1 = 384, f2_conv1 = 192, f2_conv3 = 384, f3_conv1 = 48, \n",
        "                      f3_conv5 = 128, f4 = 128)\n",
        "\n",
        "  # Global Average pooling layer \n",
        "  X = GlobalAveragePooling2D(name = 'GAPL')(X)\n",
        "\n",
        "  # Dropoutlayer \n",
        "  X = Dropout(0.4)(X)\n",
        "\n",
        "  # output layer \n",
        "  X = Dense(1000, activation = 'softmax')(X)\n",
        "  \n",
        "  # model\n",
        "  model = Model(input_layer, [X, X1, X2], name = 'GoogLeNet')\n",
        "\n",
        "  return model\n",
        "\n",
        "model = GoogLeNet()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2126aZ56nrL"
      },
      "source": [
        "#### **3.1.3 Model Summary**\n",
        "The model.summary() method call prints a summary of the NN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7O3139AanAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8bc408-688b-4931-ed12-5b4fcae6b3ed"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"GoogLeNet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 109, 109, 64) 9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 54, 54, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 54, 54, 192)  110784      conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 192)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 26, 26, 96)   18528       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 26, 26, 16)   3088        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 26, 26, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 26, 26, 64)   12352       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 26, 26, 128)  110720      conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 26, 26, 32)   12832       conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 26, 26, 32)   6176        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 26, 26, 256)  0           conv2d_3[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 26, 26, 128)  32896       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 26, 26, 32)   8224        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 26, 26, 256)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 26, 26, 128)  32896       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 26, 26, 192)  221376      conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 26, 26, 96)   76896       conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 26, 26, 64)   16448       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 26, 26, 480)  0           conv2d_9[0][0]                   \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 480)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 12, 12, 96)   46176       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 12, 12, 16)   7696        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 12, 12, 480)  0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 12, 12, 192)  92352       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 12, 12, 208)  179920      conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 12, 12, 48)   19248       conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 12, 12, 64)   30784       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 12, 12, 512)  0           conv2d_15[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 12, 12, 112)  57456       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 12, 12, 24)   12312       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 12, 12, 512)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 12, 12, 160)  82080       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 12, 12, 224)  226016      conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 12, 12, 64)   38464       conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 12, 12, 64)   32832       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 12, 12, 512)  0           conv2d_22[0][0]                  \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 12, 12, 128)  65664       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 24)   12312       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 12, 12, 512)  0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 12, 12, 128)  65664       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 256)  295168      conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 64)   38464       conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 64)   32832       max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 12, 12, 512)  0           conv2d_28[0][0]                  \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 144)  73872       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 32)   16416       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 12, 12, 512)  0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 112)  57456       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 288)  373536      conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 64)   51264       conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 64)   32832       max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 12, 12, 528)  0           conv2d_34[0][0]                  \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  84640       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 32)   16928       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 12, 12, 528)  0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 256)  135424      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 320)  461120      conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 128)  102528      conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 128)  67712       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 12, 12, 832)  0           conv2d_41[0][0]                  \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 5, 5, 832)    0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 5, 5, 160)    133280      max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 5, 5, 32)     26656       max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 5, 5, 832)    0           max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 5, 5, 256)    213248      max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 5, 5, 320)    461120      conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 5, 5, 128)    102528      conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 5, 5, 128)    106624      max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 5, 5, 832)    0           conv2d_47[0][0]                  \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 5, 5, 192)    159936      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 5, 5, 48)     39984       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 5, 5, 832)    0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 3, 3, 512)    0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 3, 3, 528)    0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 5, 5, 384)    319872      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 5, 5, 384)    663936      conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 5, 5, 128)    153728      conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 5, 5, 128)    106624      max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 3, 3, 128)    65664       average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 3, 3, 128)    67712       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 5, 5, 1024)   0           conv2d_53[0][0]                  \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "                                                                 conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1152)         0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1152)         0           conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "GAPL (GlobalAveragePooling2D)   (None, 1024)         0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         1180672     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         1180672     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           GAPL[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1000)         1025000     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 5)            5125        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1000)         1025000     dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 10,523,397\n",
            "Trainable params: 10,523,397\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LTya9ES7mJk"
      },
      "source": [
        "####**3.1.4 Model Compiling/Execution**\n",
        "\n",
        "The \"output shape\" column shows the transformation of the dimensions of each layer as a result of the convolution and max pooling - convolution will reduce the layer size by a bit due to padding, and max pooling will halve the output size.\n",
        "\n",
        "\n",
        "Next, we'll configure the specifications for model training. We will train our model with the binary_crossentropy loss. We will use the Adam optimizer. Adam is a sensible optimization algorithm because it automates learning-rate tuning for us (alternatively, we could also use RmsProp and Adagrad for similar results). We will add accuracy to metrics so that the model will monitor accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIVr3vAEatSU"
      },
      "source": [
        "#add loss function and optimisers\n",
        "#model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics =['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F14ideQ8wje2"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "#model.compile(loss='sparse_categorical_crossentropy',\n",
        "#               optimizer=RMSprop(lr=0.001),\n",
        " #              metrics=['accuracy', tf.keras.metrics.AUC()])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'Adam', loss='sparse_categorical_crossentropy', metrics =['accuracy'])\n",
        "#model.compile(optimizer=RMSprop(lr=0.01), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRuolfLI8fdY"
      },
      "source": [
        "####**3.1.5 Fitting the Model(Training)**\n",
        "Let's train for 25 epochs GPU connection:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icgxL51Ba5Kd",
        "outputId": "a05f015c-598e-4649-9cc6-c38a7b08362e"
      },
      "source": [
        "# epochs is 15  \n",
        "google_fit_without_tl = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=32,  \n",
        "      epochs=25,\n",
        "      verbose=1,\n",
        "      validation_data = test_generator,\n",
        "      validation_steps=16)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "32/32 [==============================] - 59s 709ms/step - loss: 8.7522 - dense_4_loss: 4.2917 - dense_1_loss: 1.0674 - dense_3_loss: 3.3931 - dense_4_accuracy: 0.4107 - dense_1_accuracy: 0.4932 - dense_3_accuracy: 0.4303 - val_loss: 1.9714 - val_dense_4_loss: 0.6536 - val_dense_1_loss: 0.6546 - val_dense_3_loss: 0.6631 - val_dense_4_accuracy: 0.6367 - val_dense_1_accuracy: 0.6367 - val_dense_3_accuracy: 0.6367\n",
            "Epoch 2/25\n",
            "32/32 [==============================] - 20s 627ms/step - loss: 2.0753 - dense_4_loss: 0.6761 - dense_1_loss: 0.6799 - dense_3_loss: 0.7193 - dense_4_accuracy: 0.6143 - dense_1_accuracy: 0.6256 - dense_3_accuracy: 0.5894 - val_loss: 2.0453 - val_dense_4_loss: 0.6828 - val_dense_1_loss: 0.6811 - val_dense_3_loss: 0.6814 - val_dense_4_accuracy: 0.5859 - val_dense_1_accuracy: 0.5859 - val_dense_3_accuracy: 0.5859\n",
            "Epoch 3/25\n",
            "32/32 [==============================] - 20s 612ms/step - loss: 2.0617 - dense_4_loss: 0.6942 - dense_1_loss: 0.6880 - dense_3_loss: 0.6794 - dense_4_accuracy: 0.5818 - dense_1_accuracy: 0.5815 - dense_3_accuracy: 0.5956 - val_loss: 1.9894 - val_dense_4_loss: 0.6649 - val_dense_1_loss: 0.6621 - val_dense_3_loss: 0.6624 - val_dense_4_accuracy: 0.6250 - val_dense_1_accuracy: 0.6250 - val_dense_3_accuracy: 0.6250\n",
            "Epoch 4/25\n",
            "32/32 [==============================] - 20s 616ms/step - loss: 1.9957 - dense_4_loss: 0.6701 - dense_1_loss: 0.6546 - dense_3_loss: 0.6709 - dense_4_accuracy: 0.6272 - dense_1_accuracy: 0.6382 - dense_3_accuracy: 0.5828 - val_loss: 1.8852 - val_dense_4_loss: 0.6287 - val_dense_1_loss: 0.6266 - val_dense_3_loss: 0.6299 - val_dense_4_accuracy: 0.6797 - val_dense_1_accuracy: 0.6797 - val_dense_3_accuracy: 0.6797\n",
            "Epoch 5/25\n",
            "32/32 [==============================] - 20s 609ms/step - loss: 2.0129 - dense_4_loss: 0.6680 - dense_1_loss: 0.6663 - dense_3_loss: 0.6787 - dense_4_accuracy: 0.6217 - dense_1_accuracy: 0.6301 - dense_3_accuracy: 0.6103 - val_loss: 1.9916 - val_dense_4_loss: 0.6668 - val_dense_1_loss: 0.6614 - val_dense_3_loss: 0.6634 - val_dense_4_accuracy: 0.6289 - val_dense_1_accuracy: 0.6289 - val_dense_3_accuracy: 0.6289\n",
            "Epoch 6/25\n",
            "32/32 [==============================] - 19s 605ms/step - loss: 2.0772 - dense_4_loss: 0.6970 - dense_1_loss: 0.6793 - dense_3_loss: 0.7009 - dense_4_accuracy: 0.5883 - dense_1_accuracy: 0.5990 - dense_3_accuracy: 0.5619 - val_loss: 2.0221 - val_dense_4_loss: 0.6750 - val_dense_1_loss: 0.6727 - val_dense_3_loss: 0.6744 - val_dense_4_accuracy: 0.5977 - val_dense_1_accuracy: 0.5977 - val_dense_3_accuracy: 0.5977\n",
            "Epoch 7/25\n",
            "32/32 [==============================] - 19s 598ms/step - loss: 2.0325 - dense_4_loss: 0.6752 - dense_1_loss: 0.6723 - dense_3_loss: 0.6849 - dense_4_accuracy: 0.6277 - dense_1_accuracy: 0.6267 - dense_3_accuracy: 0.5938 - val_loss: 1.9293 - val_dense_4_loss: 0.6438 - val_dense_1_loss: 0.6422 - val_dense_3_loss: 0.6433 - val_dense_4_accuracy: 0.6562 - val_dense_1_accuracy: 0.6562 - val_dense_3_accuracy: 0.6562\n",
            "Epoch 8/25\n",
            "32/32 [==============================] - 19s 589ms/step - loss: 2.0901 - dense_4_loss: 0.6867 - dense_1_loss: 0.6955 - dense_3_loss: 0.7080 - dense_4_accuracy: 0.5852 - dense_1_accuracy: 0.6030 - dense_3_accuracy: 0.5468 - val_loss: 1.9637 - val_dense_4_loss: 0.6533 - val_dense_1_loss: 0.6526 - val_dense_3_loss: 0.6578 - val_dense_4_accuracy: 0.6406 - val_dense_1_accuracy: 0.6406 - val_dense_3_accuracy: 0.6406\n",
            "Epoch 9/25\n",
            "32/32 [==============================] - 19s 599ms/step - loss: 2.0168 - dense_4_loss: 0.6734 - dense_1_loss: 0.6684 - dense_3_loss: 0.6750 - dense_4_accuracy: 0.6312 - dense_1_accuracy: 0.6219 - dense_3_accuracy: 0.6238 - val_loss: 1.9253 - val_dense_4_loss: 0.6405 - val_dense_1_loss: 0.6449 - val_dense_3_loss: 0.6399 - val_dense_4_accuracy: 0.6602 - val_dense_1_accuracy: 0.6602 - val_dense_3_accuracy: 0.6602\n",
            "Epoch 10/25\n",
            "32/32 [==============================] - 19s 591ms/step - loss: 1.9561 - dense_4_loss: 0.6560 - dense_1_loss: 0.6468 - dense_3_loss: 0.6534 - dense_4_accuracy: 0.6592 - dense_1_accuracy: 0.6564 - dense_3_accuracy: 0.6613 - val_loss: 2.0347 - val_dense_4_loss: 0.6864 - val_dense_1_loss: 0.6703 - val_dense_3_loss: 0.6780 - val_dense_4_accuracy: 0.6094 - val_dense_1_accuracy: 0.6094 - val_dense_3_accuracy: 0.6094\n",
            "Epoch 11/25\n",
            "32/32 [==============================] - 19s 581ms/step - loss: 2.0707 - dense_4_loss: 0.6917 - dense_1_loss: 0.6796 - dense_3_loss: 0.6994 - dense_4_accuracy: 0.5892 - dense_1_accuracy: 0.5953 - dense_3_accuracy: 0.5902 - val_loss: 1.9369 - val_dense_4_loss: 0.6532 - val_dense_1_loss: 0.6412 - val_dense_3_loss: 0.6425 - val_dense_4_accuracy: 0.6797 - val_dense_1_accuracy: 0.6797 - val_dense_3_accuracy: 0.6797\n",
            "Epoch 12/25\n",
            "32/32 [==============================] - 18s 574ms/step - loss: 2.0101 - dense_4_loss: 0.6689 - dense_1_loss: 0.6654 - dense_3_loss: 0.6758 - dense_4_accuracy: 0.6310 - dense_1_accuracy: 0.6270 - dense_3_accuracy: 0.6209 - val_loss: 1.9355 - val_dense_4_loss: 0.6465 - val_dense_1_loss: 0.6425 - val_dense_3_loss: 0.6464 - val_dense_4_accuracy: 0.6602 - val_dense_1_accuracy: 0.6602 - val_dense_3_accuracy: 0.6602\n",
            "Epoch 13/25\n",
            "32/32 [==============================] - 18s 571ms/step - loss: 2.0420 - dense_4_loss: 0.6739 - dense_1_loss: 0.6776 - dense_3_loss: 0.6905 - dense_4_accuracy: 0.6117 - dense_1_accuracy: 0.6162 - dense_3_accuracy: 0.5943 - val_loss: 1.9663 - val_dense_4_loss: 0.6566 - val_dense_1_loss: 0.6545 - val_dense_3_loss: 0.6552 - val_dense_4_accuracy: 0.6367 - val_dense_1_accuracy: 0.6367 - val_dense_3_accuracy: 0.6367\n",
            "Epoch 14/25\n",
            "32/32 [==============================] - 18s 568ms/step - loss: 2.0140 - dense_4_loss: 0.6764 - dense_1_loss: 0.6639 - dense_3_loss: 0.6737 - dense_4_accuracy: 0.6235 - dense_1_accuracy: 0.6219 - dense_3_accuracy: 0.6081 - val_loss: 1.8852 - val_dense_4_loss: 0.6312 - val_dense_1_loss: 0.6246 - val_dense_3_loss: 0.6293 - val_dense_4_accuracy: 0.6992 - val_dense_1_accuracy: 0.6992 - val_dense_3_accuracy: 0.6992\n",
            "Epoch 15/25\n",
            "32/32 [==============================] - 18s 577ms/step - loss: 1.9529 - dense_4_loss: 0.6509 - dense_1_loss: 0.6459 - dense_3_loss: 0.6561 - dense_4_accuracy: 0.6605 - dense_1_accuracy: 0.6593 - dense_3_accuracy: 0.6469 - val_loss: 2.0473 - val_dense_4_loss: 0.6901 - val_dense_1_loss: 0.6766 - val_dense_3_loss: 0.6807 - val_dense_4_accuracy: 0.6133 - val_dense_1_accuracy: 0.6133 - val_dense_3_accuracy: 0.6133\n",
            "Epoch 16/25\n",
            "32/32 [==============================] - 19s 576ms/step - loss: 2.1455 - dense_4_loss: 0.7228 - dense_1_loss: 0.7095 - dense_3_loss: 0.7132 - dense_4_accuracy: 0.5550 - dense_1_accuracy: 0.5712 - dense_3_accuracy: 0.5469 - val_loss: 2.0173 - val_dense_4_loss: 0.6764 - val_dense_1_loss: 0.6661 - val_dense_3_loss: 0.6748 - val_dense_4_accuracy: 0.6094 - val_dense_1_accuracy: 0.6094 - val_dense_3_accuracy: 0.6094\n",
            "Epoch 17/25\n",
            "32/32 [==============================] - 18s 561ms/step - loss: 1.9642 - dense_4_loss: 0.6590 - dense_1_loss: 0.6374 - dense_3_loss: 0.6678 - dense_4_accuracy: 0.6499 - dense_1_accuracy: 0.6693 - dense_3_accuracy: 0.6533 - val_loss: 1.9052 - val_dense_4_loss: 0.6397 - val_dense_1_loss: 0.6349 - val_dense_3_loss: 0.6306 - val_dense_4_accuracy: 0.6836 - val_dense_1_accuracy: 0.6836 - val_dense_3_accuracy: 0.6836\n",
            "Epoch 18/25\n",
            "32/32 [==============================] - 18s 560ms/step - loss: 1.9980 - dense_4_loss: 0.6574 - dense_1_loss: 0.6646 - dense_3_loss: 0.6760 - dense_4_accuracy: 0.6341 - dense_1_accuracy: 0.6358 - dense_3_accuracy: 0.6331 - val_loss: 1.9701 - val_dense_4_loss: 0.6582 - val_dense_1_loss: 0.6546 - val_dense_3_loss: 0.6573 - val_dense_4_accuracy: 0.6328 - val_dense_1_accuracy: 0.6328 - val_dense_3_accuracy: 0.6328\n",
            "Epoch 19/25\n",
            "32/32 [==============================] - 18s 554ms/step - loss: 1.9545 - dense_4_loss: 0.6478 - dense_1_loss: 0.6475 - dense_3_loss: 0.6592 - dense_4_accuracy: 0.6629 - dense_1_accuracy: 0.6629 - dense_3_accuracy: 0.6550 - val_loss: 1.9782 - val_dense_4_loss: 0.6597 - val_dense_1_loss: 0.6591 - val_dense_3_loss: 0.6595 - val_dense_4_accuracy: 0.6289 - val_dense_1_accuracy: 0.6289 - val_dense_3_accuracy: 0.6289\n",
            "Epoch 20/25\n",
            "32/32 [==============================] - 18s 568ms/step - loss: 2.0037 - dense_4_loss: 0.6594 - dense_1_loss: 0.6647 - dense_3_loss: 0.6796 - dense_4_accuracy: 0.6175 - dense_1_accuracy: 0.6219 - dense_3_accuracy: 0.6032 - val_loss: 2.0967 - val_dense_4_loss: 0.7008 - val_dense_1_loss: 0.7077 - val_dense_3_loss: 0.6882 - val_dense_4_accuracy: 0.5977 - val_dense_1_accuracy: 0.5977 - val_dense_3_accuracy: 0.5977\n",
            "Epoch 21/25\n",
            "32/32 [==============================] - 18s 559ms/step - loss: 2.0299 - dense_4_loss: 0.6804 - dense_1_loss: 0.6710 - dense_3_loss: 0.6785 - dense_4_accuracy: 0.6203 - dense_1_accuracy: 0.6204 - dense_3_accuracy: 0.6193 - val_loss: 1.9188 - val_dense_4_loss: 0.6403 - val_dense_1_loss: 0.6384 - val_dense_3_loss: 0.6402 - val_dense_4_accuracy: 0.6641 - val_dense_1_accuracy: 0.6641 - val_dense_3_accuracy: 0.6641\n",
            "Epoch 22/25\n",
            "32/32 [==============================] - 18s 551ms/step - loss: 1.9780 - dense_4_loss: 0.6579 - dense_1_loss: 0.6517 - dense_3_loss: 0.6684 - dense_4_accuracy: 0.6404 - dense_1_accuracy: 0.6372 - dense_3_accuracy: 0.6412 - val_loss: 2.0228 - val_dense_4_loss: 0.6794 - val_dense_1_loss: 0.6676 - val_dense_3_loss: 0.6757 - val_dense_4_accuracy: 0.6055 - val_dense_1_accuracy: 0.6055 - val_dense_3_accuracy: 0.6055\n",
            "Epoch 23/25\n",
            "32/32 [==============================] - 21s 642ms/step - loss: 2.0273 - dense_4_loss: 0.6735 - dense_1_loss: 0.6762 - dense_3_loss: 0.6776 - dense_4_accuracy: 0.6190 - dense_1_accuracy: 0.6111 - dense_3_accuracy: 0.6131 - val_loss: 1.9899 - val_dense_4_loss: 0.6655 - val_dense_1_loss: 0.6592 - val_dense_3_loss: 0.6652 - val_dense_4_accuracy: 0.6172 - val_dense_1_accuracy: 0.6172 - val_dense_3_accuracy: 0.6172\n",
            "Epoch 24/25\n",
            "32/32 [==============================] - 18s 545ms/step - loss: 2.0033 - dense_4_loss: 0.6693 - dense_1_loss: 0.6654 - dense_3_loss: 0.6687 - dense_4_accuracy: 0.6183 - dense_1_accuracy: 0.6150 - dense_3_accuracy: 0.6171 - val_loss: 2.0056 - val_dense_4_loss: 0.6695 - val_dense_1_loss: 0.6676 - val_dense_3_loss: 0.6686 - val_dense_4_accuracy: 0.6094 - val_dense_1_accuracy: 0.6094 - val_dense_3_accuracy: 0.6094\n",
            "Epoch 25/25\n",
            "32/32 [==============================] - 18s 553ms/step - loss: 1.9444 - dense_4_loss: 0.6491 - dense_1_loss: 0.6437 - dense_3_loss: 0.6515 - dense_4_accuracy: 0.6625 - dense_1_accuracy: 0.6621 - dense_3_accuracy: 0.6557 - val_loss: 1.9706 - val_dense_4_loss: 0.6603 - val_dense_1_loss: 0.6519 - val_dense_3_loss: 0.6584 - val_dense_4_accuracy: 0.6328 - val_dense_1_accuracy: 0.6328 - val_dense_3_accuracy: 0.6328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aTxt25gxNPD"
      },
      "source": [
        "###**3.2: Transfer Learning with GoogLeNet Architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2fPJVMMxbIX"
      },
      "source": [
        "####**3.2.1 Creating Transfer Learning Architecture using GoogLenet Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1OcTw2QtCdN",
        "outputId": "b0495b98-e16a-4d19-911f-1a76e14fe59d"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(InceptionV3(include_top = False, weights=\"imagenet\", input_shape=(224, 224, 3)))\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNb9vA_Ex-BO"
      },
      "source": [
        "####**3.2.2 Model Compilation/Execution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8usiAemNtacG"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "               optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['accuracy', tf.keras.metrics.AUC()])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvwc0nTnyVud"
      },
      "source": [
        "####**3.2.3 Fitting the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X6x0kA-t1a1",
        "outputId": "1e8ad696-f431-46c0-9447-6ce04549b8b8"
      },
      "source": [
        "Google_fit_with_tl = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=32,  \n",
        "      epochs=25,\n",
        "      verbose=1,\n",
        "      validation_data = test_generator,\n",
        "      validation_steps=16)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "32/32 [==============================] - 22s 513ms/step - loss: 0.7724 - accuracy: 0.5779 - auc_3: 0.5560 - val_loss: 0.6732 - val_accuracy: 0.5703 - val_auc_3: 0.5775\n",
            "Epoch 2/25\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.6893 - accuracy: 0.6060 - auc_3: 0.5793 - val_loss: 0.9183 - val_accuracy: 0.6211 - val_auc_3: 0.6229\n",
            "Epoch 3/25\n",
            "32/32 [==============================] - 15s 455ms/step - loss: 0.7188 - accuracy: 0.6040 - auc_3: 0.5808 - val_loss: 0.6675 - val_accuracy: 0.6641 - val_auc_3: 0.6485\n",
            "Epoch 4/25\n",
            "32/32 [==============================] - 16s 488ms/step - loss: 0.6449 - accuracy: 0.6460 - auc_3: 0.6228 - val_loss: 0.6314 - val_accuracy: 0.6289 - val_auc_3: 0.6664\n",
            "Epoch 5/25\n",
            "32/32 [==============================] - 14s 452ms/step - loss: 0.6914 - accuracy: 0.5911 - auc_3: 0.5961 - val_loss: 0.6518 - val_accuracy: 0.6758 - val_auc_3: 0.6124\n",
            "Epoch 6/25\n",
            "32/32 [==============================] - 15s 454ms/step - loss: 0.6198 - accuracy: 0.6656 - auc_3: 0.6396 - val_loss: 0.6020 - val_accuracy: 0.6914 - val_auc_3: 0.6417\n",
            "Epoch 7/25\n",
            "32/32 [==============================] - 15s 456ms/step - loss: 0.6590 - accuracy: 0.6237 - auc_3: 0.6461 - val_loss: 0.5703 - val_accuracy: 0.6719 - val_auc_3: 0.7308\n",
            "Epoch 8/25\n",
            "32/32 [==============================] - 14s 452ms/step - loss: 0.6366 - accuracy: 0.6366 - auc_3: 0.6489 - val_loss: 0.6451 - val_accuracy: 0.6289 - val_auc_3: 0.6635\n",
            "Epoch 9/25\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.6678 - accuracy: 0.6189 - auc_3: 0.6252 - val_loss: 0.6750 - val_accuracy: 0.6016 - val_auc_3: 0.7502\n",
            "Epoch 10/25\n",
            "32/32 [==============================] - 15s 455ms/step - loss: 0.6249 - accuracy: 0.6566 - auc_3: 0.6657 - val_loss: 0.5964 - val_accuracy: 0.6836 - val_auc_3: 0.7200\n",
            "Epoch 11/25\n",
            "32/32 [==============================] - 15s 455ms/step - loss: 0.6689 - accuracy: 0.6484 - auc_3: 0.6415 - val_loss: 0.5732 - val_accuracy: 0.7109 - val_auc_3: 0.7001\n",
            "Epoch 12/25\n",
            "32/32 [==============================] - 14s 453ms/step - loss: 0.5863 - accuracy: 0.7024 - auc_3: 0.7015 - val_loss: 0.7909 - val_accuracy: 0.6094 - val_auc_3: 0.6928\n",
            "Epoch 13/25\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6056 - accuracy: 0.6767 - auc_3: 0.7010 - val_loss: 0.6928 - val_accuracy: 0.5977 - val_auc_3: 0.6671\n",
            "Epoch 14/25\n",
            "32/32 [==============================] - 14s 452ms/step - loss: 0.5975 - accuracy: 0.6759 - auc_3: 0.7190 - val_loss: 0.5791 - val_accuracy: 0.6680 - val_auc_3: 0.7228\n",
            "Epoch 15/25\n",
            "32/32 [==============================] - 15s 454ms/step - loss: 0.5874 - accuracy: 0.6919 - auc_3: 0.7011 - val_loss: 0.6626 - val_accuracy: 0.6211 - val_auc_3: 0.6738\n",
            "Epoch 16/25\n",
            "32/32 [==============================] - 15s 454ms/step - loss: 0.6042 - accuracy: 0.6596 - auc_3: 0.6963 - val_loss: 0.6053 - val_accuracy: 0.6641 - val_auc_3: 0.7229\n",
            "Epoch 17/25\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.6275 - accuracy: 0.6541 - auc_3: 0.6687 - val_loss: 0.5741 - val_accuracy: 0.7031 - val_auc_3: 0.7253\n",
            "Epoch 18/25\n",
            "32/32 [==============================] - 14s 442ms/step - loss: 0.6366 - accuracy: 0.6639 - auc_3: 0.6765 - val_loss: 0.5656 - val_accuracy: 0.7227 - val_auc_3: 0.7432\n",
            "Epoch 19/25\n",
            "32/32 [==============================] - 14s 434ms/step - loss: 0.5952 - accuracy: 0.6887 - auc_3: 0.6990 - val_loss: 0.5937 - val_accuracy: 0.6758 - val_auc_3: 0.6893\n",
            "Epoch 20/25\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.6044 - accuracy: 0.6630 - auc_3: 0.6571 - val_loss: 0.6501 - val_accuracy: 0.6562 - val_auc_3: 0.6759\n",
            "Epoch 21/25\n",
            "32/32 [==============================] - 14s 444ms/step - loss: 0.6587 - accuracy: 0.6058 - auc_3: 0.6392 - val_loss: 0.5548 - val_accuracy: 0.7109 - val_auc_3: 0.7516\n",
            "Epoch 22/25\n",
            "32/32 [==============================] - 14s 442ms/step - loss: 0.5910 - accuracy: 0.6845 - auc_3: 0.7148 - val_loss: 0.5587 - val_accuracy: 0.6680 - val_auc_3: 0.7458\n",
            "Epoch 23/25\n",
            "32/32 [==============================] - 14s 436ms/step - loss: 0.5703 - accuracy: 0.7139 - auc_3: 0.7353 - val_loss: 0.6608 - val_accuracy: 0.6562 - val_auc_3: 0.7009\n",
            "Epoch 24/25\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.5637 - accuracy: 0.7025 - auc_3: 0.7590 - val_loss: 0.5918 - val_accuracy: 0.6758 - val_auc_3: 0.7146\n",
            "Epoch 25/25\n",
            "32/32 [==============================] - 14s 442ms/step - loss: 0.6384 - accuracy: 0.6544 - auc_3: 0.6615 - val_loss: 0.5790 - val_accuracy: 0.7109 - val_auc_3: 0.7323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F5mV8WCAC1E"
      },
      "source": [
        "###**4. Image Classification and Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOlDqL4_e-68",
        "outputId": "37a4c21e-8e05-46b5-9a2a-92a6638825f9"
      },
      "source": [
        "model.evaluate(test_generator)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "386/386 [==============================] - 66s 170ms/step - loss: 0.5945 - accuracy: 0.6813 - auc_3: 0.7235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5944951176643372, 0.6813240051269531, 0.7235076427459717]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcM8E_86kbhV",
        "outputId": "210b2a92-570f-4223-88f2-3989c8f3adcf"
      },
      "source": [
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "test_generator.reset()\n",
        "preds = model.predict(test_generator, \n",
        "                      verbose=1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "386/386 [==============================] - 65s 166ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEBzfCVSnoWK",
        "outputId": "4359332e-026e-4e5f-a408-aa231bddae83"
      },
      "source": [
        "print(len(test_generator.classes))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1GoYesqzEn-"
      },
      "source": [
        "###**5. Metrics Calculation**\n",
        "\n",
        "Now, calculating the ROC curve and plot it.\n",
        "\n",
        "First, let's make predictions on our test set. When using generators to make predictions, we must first turn off shuffle (as we did when we created validation_generator) and reset the generator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xadxc75p4bM"
      },
      "source": [
        "fpr, tpr, threshold = metrics.roc_curve(test_generator.classes, preds )"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1SisekagYou"
      },
      "source": [
        "roc_auc = metrics.auc(fpr, tpr)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "SrC7IxqAgfl8",
        "outputId": "dd1aa014-0985-48b5-b42a-68c4cb98acb2"
      },
      "source": [
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}