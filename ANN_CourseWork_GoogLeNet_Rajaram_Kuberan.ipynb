{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN CourseWork - Rajaram Kuberan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/ANN_CourseWork_GoogLeNet_Rajaram_Kuberan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPf6LfXSdxe2"
      },
      "source": [
        "# **7088 CEM - Artificial Neural Network Coursework**\n",
        "##**Coventry University**\n",
        "###**Student Name**: Rajaram Kuberan\n",
        "###**Student ID**  : 10457647\n",
        "###**Email ID**    : kuberanr@coventry.ac.uk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLhhpL_PkRlY"
      },
      "source": [
        "# **Topic: Image Classification of Grocery Items for Ketogenic Shopping Using CNN Architectures**\n",
        "\n",
        "This project Worflow is carried out in five parts:\n",
        "\n",
        "**1. Data Collection**\n",
        "\n",
        "**2. Data Preprocessing**\n",
        "\n",
        "**3. CNN Architecture Selection and Modelling**\n",
        "\n",
        "**4. Image Classification and Prediction**\n",
        "\n",
        "**5. Metrics Calculation**\n",
        "\n",
        "There are two architectures used for this Coursework:\n",
        "\n",
        "1. GoogLeNet Architecture\n",
        "2. Transfer Learning\n",
        "\n",
        "In this Colab Notebook, the first architecture is explained: GoogLeNet Architecture without Transfer Learning and with Transfer Learning. The second  architecture - Transfer Learning using MobileNet architecture is explained in another Colab Notebook - [Link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/Transfer_Learning.ipynb)\n",
        "\n",
        "Code Link for whole project - [Github link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ.git)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-tqOU9kMEbc"
      },
      "source": [
        "##**1. Data Collection**\n",
        "\n",
        "  The dataset used for this project is not taken directly from Kaggle or UCI data repository. We have novelly scrapped the images from the UK top supermarket webistes, and also added images from two projects where grocery images were used for performing Classification.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnm4HR2SXWNl"
      },
      "source": [
        "###**1.1 Image Scrapping**\n",
        "\n",
        "  Data is collected by scrapping images from websites like [Tesco](https://www.tesco.com/groceries/) and [Morrisons](https://groceries.morrisons.com/browse). Additionally the dataset from [Grocery Dataset](https://github.com/marcusklasson/GroceryStoreDataset/tree/master/dataset) and [Freiburg Grocery Dataset](http://aisdatasets.informatik.uni-freiburg.de/freiburg_groceries_dataset/) are also used. For Image Scrapping, Automation Tool - Selenium written in Java is used in this project. The Selenium with Python was also used. But Java Selenium combination helped us to scrap nearly 1500 images in a single exection of code. In this way, we could scrap nearly 12500+ images from Tesco website and 7500+ images from Morrisons website. The Grocery and Freiburg Dataset contains 5000 images respectively. So, totally we have 30000+ images to perform Classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9eTtOhDXfph"
      },
      "source": [
        "###**1.2 Selenium Java code Link**\n",
        "\n",
        "  Below are the Github link for selenium Java code:\n",
        "\n",
        "Tesco Selenium Java codes - [Link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/Data_Image_Web_scrapping/tesco_selenium.java)\n",
        "\n",
        "Morrisons Selenium Java - [Link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/Data_Image_Web_scrapping/Morrisons_Selenium.java)\n",
        "\n",
        "Dependencies required to execute and perform Automated Image Scrapping: \n",
        "1. Chromedriver - [Link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/tree/main/Data_Image_Web_scrapping/chromedriver_win32)\n",
        "\n",
        "2. Maven Repository and Selenium Ashot - [Link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/Data_Image_Web_scrapping/selenium_ashot.txt)\n",
        "\n",
        "3. XML Pom file where the dependencies are listed to run the Java Selenium code: [Link](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/Data_Image_Web_scrapping/Automation/Images/pom.xml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3yC7iuuMBso"
      },
      "source": [
        "###**1.3 Importing Data from the Github**\n",
        "\n",
        "Git clone is used to import the data from Github to Google Colab. The GPU runtime is used to run the CNN model due to its heavy computational dependencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVzozTnCeSZD",
        "outputId": "38d478f1-d7a9-4160-996c-83087112db48"
      },
      "source": [
        "!git clone https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ANN_Coursework_Coventry_Univ'...\n",
            "remote: Enumerating objects: 30390, done.\u001b[K\n",
            "remote: Total 30390 (delta 0), reused 0 (delta 0), pack-reused 30390\u001b[K\n",
            "Receiving objects: 100% (30390/30390), 6.12 GiB | 17.46 MiB/s, done.\n",
            "Resolving deltas: 100% (335/335), done.\n",
            "Checking out files: 100% (31425/31425), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP1wIvcK2lcA"
      },
      "source": [
        "##**2. Data Preprocessing**\n",
        "\n",
        "In this worflow, the dataset of 30000+ images are splitted randomly in the ratio of 80:20.\n",
        "\n",
        "The images are segregated, and stored in separate folders named train and test.\n",
        "\n",
        "Splitting the data code Link: [Python Code](https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/splitting_the_data.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfDDo5X30uDh"
      },
      "source": [
        "###**2.1 Importing the Necessary Libraries**\n",
        "\n",
        "The necessary libraries are imported for performing Data Preprocessing and CNN Modelling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc83Z1_PfQ1B"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from keras.layers import concatenate\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCl02Y24uNCk"
      },
      "source": [
        "###**2.2 Image Preprocessing**\n",
        "\n",
        "In this process, ImageDataGenerator class is used to create our train and test dataset for binary classification.Moreover, data is also normalised.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDF70CK2vhgn"
      },
      "source": [
        "####**2.2.1 Data/Image Normalisation**\n",
        "\n",
        "It's important to normalize our data because most of the CNN architecture accepts images in particular pixel values to improve its overall performance. The GoogLeNet Architecture accepts inputs with pixel 224x224.\n",
        "\n",
        "For this, the rescale parameter is used to scale our image pixel values from [0, 255] to [0,1].\n",
        "\n",
        "In each generator, we specify the source directory of our images, the classes, the input image size, the batch size (how many images to process at once), and class mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2Hg5sXfdcN"
      },
      "source": [
        "# initialising the image size as 224x224\n",
        "IMAGE_SIZE = [224,224]\n",
        "\n",
        "\n",
        "# Setting the Path to test and train data \n",
        "test_path = '/content/ANN_Coursework_Coventry_Univ/test'\n",
        "train_path = '/content/ANN_Coursework_Coventry_Univ/train'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3Jw6oVdfgng"
      },
      "source": [
        "# transforming train data images\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "# transforming train data images\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbWmS9z7dNdJ",
        "outputId": "c6bec90d-a6aa-4731-a60e-f68e49e04c20"
      },
      "source": [
        "#training data \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/ANN_Coursework_Coventry_Univ/train',  # This is the source directory for training images\n",
        "        classes = ['Keto_train', 'Non_Keto_train'],\n",
        "        target_size=(224, 224),  # All images are resized to 224x224\n",
        "        batch_size=32,\n",
        "        # Use binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# testing data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/ANN_Coursework_Coventry_Univ/test',  # This is the source directory for test images\n",
        "        classes = ['Keto_test', 'Non_Keto_Test'],\n",
        "        target_size=(224, 224),  # All images are resized to 224x224\n",
        "        batch_size=16,\n",
        "        # Use binary labels\n",
        "        class_mode='binary')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24861 images belonging to 2 classes.\n",
            "Found 6163 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YFV6A484BT2"
      },
      "source": [
        "##**3. Building the Model**\n",
        "\n",
        "In this project, GoogLeNet Architecture is used to perform Image Classification on Ketogenic and Non-Ketogenic Food items. The Keras Library is used to build the GoogLeNet CNN architecture. The training/test datas are pushed into the Github repository.\n",
        "\n",
        "In GoogLeNet architecture, there are 4 blocks of Inception layer. Firstly to avoid repeating the layers, create the inception block function so that we can use it in the model easily.\n",
        "\n",
        "Reference: Szegedy, Christian, et al. “Going deeper with convolutions.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.\n",
        "\n",
        "The above 2015 Paper is used as the reference to create the blocks. The kernel size and the convolution layers are \n",
        "exactly written in Python using Keras Library as mentioned in the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qWEOGnhwh06"
      },
      "source": [
        "### **3.1 GoogLeNet Architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtIVSrCq3B7v"
      },
      "source": [
        "####**3.1.1 Create the Inception Blocks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH1JWROnijcp"
      },
      "source": [
        "# create an Inception block \n",
        "def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4): \n",
        "  \n",
        "  # 1st block:\n",
        "  block1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', \n",
        "                 activation = 'relu')(input_layer)\n",
        "\n",
        "  # 2nd block:\n",
        "  block2 = Conv2D(filters = f2_conv1, kernel_size = (1,1), padding = 'same', \n",
        "                 activation = 'relu')(input_layer)\n",
        "  block2 = Conv2D(filters = f2_conv3, kernel_size = (3,3), padding = 'same', \n",
        "                 activation = 'relu')(block2)\n",
        "\n",
        "  # 3rd block:\n",
        "  block3 = Conv2D(filters = f3_conv1, kernel_size = (1,1), padding = 'same', \n",
        "                 activation = 'relu')(input_layer)\n",
        "  block3 = Conv2D(filters = f3_conv5, kernel_size = (5,5), padding = 'same', \n",
        "                 activation = 'relu')(block3)\n",
        "\n",
        "  # 4th block:\n",
        "  block4 = MaxPooling2D((3,3), strides= (1,1), padding = 'same')(input_layer)\n",
        "  block4 = Conv2D(filters = f4, kernel_size = (1,1), padding = 'same', \n",
        "                 activation = 'relu')(block4)\n",
        "\n",
        "  output_layer = concatenate([block1, block2, block3, block4], axis = -1)\n",
        "\n",
        "  return output_layer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR0h0jwR4buV"
      },
      "source": [
        "#### **3.1.2 Create a GoogLenet Layer**\n",
        " Here we will define GoogLeNet Model Layers and then return the model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lFYlnY7ajrG"
      },
      "source": [
        "def GoogLeNet():\n",
        "  # input layer \n",
        "  input_layer = Input(shape = (224, 224, 3))\n",
        "\n",
        "  # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
        "  X = Conv2D(filters = 64, kernel_size = (7,7), strides = 2, padding = 'valid', \n",
        "             activation = 'relu')(input_layer)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
        "\n",
        "  # convolutional layer: filters = 64, strides = 1\n",
        "  X = Conv2D(filters = 64, kernel_size = (1,1), strides = 1, padding = 'same', \n",
        "             activation = 'relu')(X)\n",
        "\n",
        "  # convolutional layer: filters = 192, kernel_size = (3,3)\n",
        "  X = Conv2D(filters = 192, kernel_size = (3,3), padding = 'same', \n",
        "             activation = 'relu')(X)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
        "\n",
        "  # 1st Inception block\n",
        "  X = Inception_block(X, f1 = 64, f2_conv1 = 96, f2_conv3 = 128, f3_conv1 = 16, \n",
        "                      f3_conv5 = 32, f4 = 32)\n",
        "\n",
        "  # 2nd Inception block\n",
        "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 192, f3_conv1 = 32, \n",
        "                      f3_conv5 = 96, f4 = 64)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
        "\n",
        "  # 3rd Inception block\n",
        "  X = Inception_block(X, f1 = 192, f2_conv1 = 96, f2_conv3 = 208, f3_conv1 = 16, \n",
        "                      f3_conv5 = 48, f4 = 64)\n",
        "\n",
        "  # Average Pooling Layer 1:\n",
        "  X1 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
        "  X1 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', \n",
        "              activation = 'relu')(X1)\n",
        "  X1 = Flatten()(X1)\n",
        "  X1 = Dense(1024, activation = 'relu')(X1)\n",
        "  X1 = Dropout(0.7)(X1)\n",
        "  X1 = Dense(5, activation = 'softmax')(X1)\n",
        "\n",
        "  \n",
        "  # 4th Inception block\n",
        "  X = Inception_block(X, f1 = 160, f2_conv1 = 112, f2_conv3 = 224, f3_conv1 = 24, \n",
        "                      f3_conv5 = 64, f4 = 64)\n",
        "\n",
        "  # 5th Inception block\n",
        "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 256, f3_conv1 = 24, \n",
        "                      f3_conv5 = 64, f4 = 64)\n",
        "\n",
        "  # 6th Inception block\n",
        "  X = Inception_block(X, f1 = 112, f2_conv1 = 144, f2_conv3 = 288, f3_conv1 = 32, \n",
        "                      f3_conv5 = 64, f4 = 64)\n",
        "\n",
        "  # Average Pooling Layer 2:\n",
        "  X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
        "  X2 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', \n",
        "              activation = 'relu')(X2)\n",
        "  X2 = Flatten()(X2)\n",
        "  X2 = Dense(1024, activation = 'relu')(X2)\n",
        "  X2 = Dropout(0.7)(X2)\n",
        "  X2 = Dense(1000, activation = 'softmax')(X2)\n",
        "  \n",
        "  \n",
        "  # 7th Inception block\n",
        "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, \n",
        "                      f3_conv5 = 128, f4 = 128)\n",
        "\n",
        "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
        "\n",
        "  # 8th Inception block\n",
        "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, \n",
        "                      f3_conv5 = 128, f4 = 128)\n",
        "\n",
        "  # 9th Inception block\n",
        "  X = Inception_block(X, f1 = 384, f2_conv1 = 192, f2_conv3 = 384, f3_conv1 = 48, \n",
        "                      f3_conv5 = 128, f4 = 128)\n",
        "\n",
        "  # Global Average pooling layer \n",
        "  X = GlobalAveragePooling2D(name = 'GAPL')(X)\n",
        "\n",
        "  # Dropoutlayer \n",
        "  X = Dropout(0.4)(X)\n",
        "\n",
        "  # output layer \n",
        "  X = Dense(1000, activation = 'softmax')(X)\n",
        "  \n",
        "  # model\n",
        "  model = Model(input_layer, [X, X1, X2], name = 'GoogLeNet')\n",
        "\n",
        "  return model\n",
        "\n",
        "model = GoogLeNet()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2126aZ56nrL"
      },
      "source": [
        "#### **3.1.3 Model Summary**\n",
        "The model.summary() method call prints a summary of the GoogLenet architectuture. The total number of parameters is equal to 10,523,397. To perform computation of nearly 1 Million parameters - High Performance Computing Machines, GPU/TPU is required. In this project, Google Colab's GPU is used to train and fit the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7O3139AanAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15500a93-40ce-428e-a6aa-46b4d6b6e0f4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"GoogLeNet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 109, 109, 64) 9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 54, 54, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 54, 54, 192)  110784      conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 192)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 26, 26, 96)   18528       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 26, 26, 16)   3088        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 26, 26, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 26, 26, 64)   12352       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 26, 26, 128)  110720      conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 26, 26, 32)   12832       conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 26, 26, 32)   6176        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 26, 26, 256)  0           conv2d_3[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 26, 26, 128)  32896       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 26, 26, 32)   8224        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 26, 26, 256)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 26, 26, 128)  32896       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 26, 26, 192)  221376      conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 26, 26, 96)   76896       conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 26, 26, 64)   16448       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 26, 26, 480)  0           conv2d_9[0][0]                   \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 480)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 12, 12, 96)   46176       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 12, 12, 16)   7696        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 12, 12, 480)  0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 12, 12, 192)  92352       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 12, 12, 208)  179920      conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 12, 12, 48)   19248       conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 12, 12, 64)   30784       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 12, 12, 512)  0           conv2d_15[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 12, 12, 112)  57456       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 12, 12, 24)   12312       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 12, 12, 512)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 12, 12, 160)  82080       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 12, 12, 224)  226016      conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 12, 12, 64)   38464       conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 12, 12, 64)   32832       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 12, 12, 512)  0           conv2d_22[0][0]                  \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 12, 12, 128)  65664       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 24)   12312       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 12, 12, 512)  0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 12, 12, 128)  65664       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 256)  295168      conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 64)   38464       conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 64)   32832       max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 12, 12, 512)  0           conv2d_28[0][0]                  \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 144)  73872       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 32)   16416       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 12, 12, 512)  0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 112)  57456       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 288)  373536      conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 64)   51264       conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 64)   32832       max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 12, 12, 528)  0           conv2d_34[0][0]                  \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  84640       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 32)   16928       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 12, 12, 528)  0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 256)  135424      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 320)  461120      conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 128)  102528      conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 128)  67712       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 12, 12, 832)  0           conv2d_41[0][0]                  \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 5, 5, 832)    0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 5, 5, 160)    133280      max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 5, 5, 32)     26656       max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 5, 5, 832)    0           max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 5, 5, 256)    213248      max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 5, 5, 320)    461120      conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 5, 5, 128)    102528      conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 5, 5, 128)    106624      max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 5, 5, 832)    0           conv2d_47[0][0]                  \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 5, 5, 192)    159936      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 5, 5, 48)     39984       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 5, 5, 832)    0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 3, 3, 512)    0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 3, 3, 528)    0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 5, 5, 384)    319872      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 5, 5, 384)    663936      conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 5, 5, 128)    153728      conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 5, 5, 128)    106624      max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 3, 3, 128)    65664       average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 3, 3, 128)    67712       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 5, 5, 1024)   0           conv2d_53[0][0]                  \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "                                                                 conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1152)         0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1152)         0           conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "GAPL (GlobalAveragePooling2D)   (None, 1024)         0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         1180672     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         1180672     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           GAPL[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1000)         1025000     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 5)            5125        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1000)         1025000     dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 10,523,397\n",
            "Trainable params: 10,523,397\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LTya9ES7mJk"
      },
      "source": [
        "####**3.1.4 Model Compiling/Execution**\n",
        "\n",
        "The \"output shape\" column shows the transformation of the dimensions of each layer as a result of the convolution and max pooling - convolution will reduce the layer size by a bit due to padding, and max pooling will halve the output size.\n",
        "\n",
        "\n",
        "Next, configure the specifications for model training. Adam optimizer is used for this model. Adam is a sensible optimization algorithm because it automates learning-rate tuning for us (alternatively, we could also use RmsProp and Adagrad for similar results). Additionally, accuracy  metrics is added so that the model will monitor accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F14ideQ8wje2"
      },
      "source": [
        "#add loss function and optimisers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "model.compile(optimizer = 'Adam', loss='sparse_categorical_crossentropy', metrics =['accuracy'])\n",
        "#model.compile(optimizer=RMSprop(lr=0.01), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRuolfLI8fdY"
      },
      "source": [
        "####**3.1.5 Fitting the Model(Training)**\n",
        "Let's train for 25 epochs GPU connection:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icgxL51Ba5Kd",
        "outputId": "fe6eb136-ec0c-40b5-9d06-38ee2bde3e10"
      },
      "source": [
        "# epochs is 25  \n",
        "google_fit_without_tl = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=32,  \n",
        "      epochs=25,\n",
        "      verbose=1,\n",
        "      validation_data = test_generator,\n",
        "      validation_steps=16)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "32/32 [==============================] - 51s 545ms/step - loss: 5.9833 - dense_4_loss: 2.5450 - dense_1_loss: 0.9224 - dense_3_loss: 2.5159 - dense_4_accuracy: 0.5040 - dense_1_accuracy: 0.5546 - dense_3_accuracy: 0.5194 - val_loss: 1.9671 - val_dense_4_loss: 0.6641 - val_dense_1_loss: 0.6459 - val_dense_3_loss: 0.6571 - val_dense_4_accuracy: 0.6641 - val_dense_1_accuracy: 0.6641 - val_dense_3_accuracy: 0.6641\n",
            "Epoch 2/25\n",
            "32/32 [==============================] - 16s 502ms/step - loss: 2.0931 - dense_4_loss: 0.6914 - dense_1_loss: 0.6823 - dense_3_loss: 0.7194 - dense_4_accuracy: 0.5927 - dense_1_accuracy: 0.6160 - dense_3_accuracy: 0.5794 - val_loss: 2.0698 - val_dense_4_loss: 0.6868 - val_dense_1_loss: 0.6954 - val_dense_3_loss: 0.6876 - val_dense_4_accuracy: 0.5625 - val_dense_1_accuracy: 0.5625 - val_dense_3_accuracy: 0.5625\n",
            "Epoch 3/25\n",
            "32/32 [==============================] - 16s 509ms/step - loss: 2.0147 - dense_4_loss: 0.6665 - dense_1_loss: 0.6671 - dense_3_loss: 0.6811 - dense_4_accuracy: 0.6209 - dense_1_accuracy: 0.6336 - dense_3_accuracy: 0.6054 - val_loss: 1.9786 - val_dense_4_loss: 0.6599 - val_dense_1_loss: 0.6575 - val_dense_3_loss: 0.6612 - val_dense_4_accuracy: 0.6367 - val_dense_1_accuracy: 0.6367 - val_dense_3_accuracy: 0.6367\n",
            "Epoch 4/25\n",
            "32/32 [==============================] - 16s 491ms/step - loss: 2.0183 - dense_4_loss: 0.6712 - dense_1_loss: 0.6619 - dense_3_loss: 0.6852 - dense_4_accuracy: 0.6413 - dense_1_accuracy: 0.6468 - dense_3_accuracy: 0.6207 - val_loss: 1.9992 - val_dense_4_loss: 0.6723 - val_dense_1_loss: 0.6554 - val_dense_3_loss: 0.6715 - val_dense_4_accuracy: 0.6367 - val_dense_1_accuracy: 0.6367 - val_dense_3_accuracy: 0.6367\n",
            "Epoch 5/25\n",
            "32/32 [==============================] - 16s 495ms/step - loss: 2.0620 - dense_4_loss: 0.6778 - dense_1_loss: 0.6826 - dense_3_loss: 0.7016 - dense_4_accuracy: 0.5853 - dense_1_accuracy: 0.6046 - dense_3_accuracy: 0.5685 - val_loss: 1.9869 - val_dense_4_loss: 0.6622 - val_dense_1_loss: 0.6632 - val_dense_3_loss: 0.6615 - val_dense_4_accuracy: 0.6250 - val_dense_1_accuracy: 0.6250 - val_dense_3_accuracy: 0.6250\n",
            "Epoch 6/25\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 2.0434 - dense_4_loss: 0.6785 - dense_1_loss: 0.6802 - dense_3_loss: 0.6847 - dense_4_accuracy: 0.5873 - dense_1_accuracy: 0.6130 - dense_3_accuracy: 0.5991 - val_loss: 2.0325 - val_dense_4_loss: 0.6797 - val_dense_1_loss: 0.6767 - val_dense_3_loss: 0.6762 - val_dense_4_accuracy: 0.5977 - val_dense_1_accuracy: 0.5977 - val_dense_3_accuracy: 0.5977\n",
            "Epoch 7/25\n",
            "32/32 [==============================] - 15s 476ms/step - loss: 2.0318 - dense_4_loss: 0.6750 - dense_1_loss: 0.6759 - dense_3_loss: 0.6810 - dense_4_accuracy: 0.6027 - dense_1_accuracy: 0.6180 - dense_3_accuracy: 0.5826 - val_loss: 1.9078 - val_dense_4_loss: 0.6338 - val_dense_1_loss: 0.6363 - val_dense_3_loss: 0.6376 - val_dense_4_accuracy: 0.6680 - val_dense_1_accuracy: 0.6680 - val_dense_3_accuracy: 0.6680\n",
            "Epoch 8/25\n",
            "32/32 [==============================] - 15s 471ms/step - loss: 1.9533 - dense_4_loss: 0.6472 - dense_1_loss: 0.6403 - dense_3_loss: 0.6658 - dense_4_accuracy: 0.6655 - dense_1_accuracy: 0.6730 - dense_3_accuracy: 0.6547 - val_loss: 1.9455 - val_dense_4_loss: 0.6420 - val_dense_1_loss: 0.6441 - val_dense_3_loss: 0.6593 - val_dense_4_accuracy: 0.6641 - val_dense_1_accuracy: 0.6641 - val_dense_3_accuracy: 0.6641\n",
            "Epoch 9/25\n",
            "32/32 [==============================] - 15s 473ms/step - loss: 2.0260 - dense_4_loss: 0.6729 - dense_1_loss: 0.6737 - dense_3_loss: 0.6794 - dense_4_accuracy: 0.6154 - dense_1_accuracy: 0.6155 - dense_3_accuracy: 0.5840 - val_loss: 1.9662 - val_dense_4_loss: 0.6591 - val_dense_1_loss: 0.6529 - val_dense_3_loss: 0.6542 - val_dense_4_accuracy: 0.6406 - val_dense_1_accuracy: 0.6406 - val_dense_3_accuracy: 0.6406\n",
            "Epoch 10/25\n",
            "32/32 [==============================] - 15s 458ms/step - loss: 2.0148 - dense_4_loss: 0.6733 - dense_1_loss: 0.6719 - dense_3_loss: 0.6696 - dense_4_accuracy: 0.6196 - dense_1_accuracy: 0.6217 - dense_3_accuracy: 0.6144 - val_loss: 1.9174 - val_dense_4_loss: 0.6391 - val_dense_1_loss: 0.6401 - val_dense_3_loss: 0.6382 - val_dense_4_accuracy: 0.6641 - val_dense_1_accuracy: 0.6641 - val_dense_3_accuracy: 0.6641\n",
            "Epoch 11/25\n",
            "32/32 [==============================] - 15s 471ms/step - loss: 1.9975 - dense_4_loss: 0.6663 - dense_1_loss: 0.6589 - dense_3_loss: 0.6723 - dense_4_accuracy: 0.6255 - dense_1_accuracy: 0.6262 - dense_3_accuracy: 0.6179 - val_loss: 1.9936 - val_dense_4_loss: 0.6736 - val_dense_1_loss: 0.6607 - val_dense_3_loss: 0.6593 - val_dense_4_accuracy: 0.6367 - val_dense_1_accuracy: 0.6367 - val_dense_3_accuracy: 0.6367\n",
            "Epoch 12/25\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 2.0041 - dense_4_loss: 0.6705 - dense_1_loss: 0.6602 - dense_3_loss: 0.6734 - dense_4_accuracy: 0.6160 - dense_1_accuracy: 0.6343 - dense_3_accuracy: 0.6282 - val_loss: 1.9129 - val_dense_4_loss: 0.6341 - val_dense_1_loss: 0.6408 - val_dense_3_loss: 0.6380 - val_dense_4_accuracy: 0.6797 - val_dense_1_accuracy: 0.6797 - val_dense_3_accuracy: 0.6797\n",
            "Epoch 13/25\n",
            "32/32 [==============================] - 14s 453ms/step - loss: 2.0219 - dense_4_loss: 0.6742 - dense_1_loss: 0.6686 - dense_3_loss: 0.6791 - dense_4_accuracy: 0.6235 - dense_1_accuracy: 0.6204 - dense_3_accuracy: 0.6257 - val_loss: 1.9781 - val_dense_4_loss: 0.6647 - val_dense_1_loss: 0.6587 - val_dense_3_loss: 0.6547 - val_dense_4_accuracy: 0.6406 - val_dense_1_accuracy: 0.6406 - val_dense_3_accuracy: 0.6406\n",
            "Epoch 14/25\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 2.0145 - dense_4_loss: 0.6745 - dense_1_loss: 0.6662 - dense_3_loss: 0.6738 - dense_4_accuracy: 0.6325 - dense_1_accuracy: 0.6251 - dense_3_accuracy: 0.6215 - val_loss: 1.9268 - val_dense_4_loss: 0.6414 - val_dense_1_loss: 0.6420 - val_dense_3_loss: 0.6434 - val_dense_4_accuracy: 0.6602 - val_dense_1_accuracy: 0.6602 - val_dense_3_accuracy: 0.6602\n",
            "Epoch 15/25\n",
            "32/32 [==============================] - 14s 452ms/step - loss: 1.9907 - dense_4_loss: 0.6665 - dense_1_loss: 0.6583 - dense_3_loss: 0.6659 - dense_4_accuracy: 0.6437 - dense_1_accuracy: 0.6421 - dense_3_accuracy: 0.6424 - val_loss: 2.0720 - val_dense_4_loss: 0.7023 - val_dense_1_loss: 0.6786 - val_dense_3_loss: 0.6911 - val_dense_4_accuracy: 0.5938 - val_dense_1_accuracy: 0.5977 - val_dense_3_accuracy: 0.5938\n",
            "Epoch 16/25\n",
            "32/32 [==============================] - 15s 458ms/step - loss: 2.0544 - dense_4_loss: 0.6839 - dense_1_loss: 0.6810 - dense_3_loss: 0.6895 - dense_4_accuracy: 0.6019 - dense_1_accuracy: 0.5953 - dense_3_accuracy: 0.5775 - val_loss: 1.9561 - val_dense_4_loss: 0.6525 - val_dense_1_loss: 0.6519 - val_dense_3_loss: 0.6517 - val_dense_4_accuracy: 0.6445 - val_dense_1_accuracy: 0.6445 - val_dense_3_accuracy: 0.6445\n",
            "Epoch 17/25\n",
            "32/32 [==============================] - 14s 442ms/step - loss: 1.9930 - dense_4_loss: 0.6577 - dense_1_loss: 0.6661 - dense_3_loss: 0.6692 - dense_4_accuracy: 0.6312 - dense_1_accuracy: 0.6310 - dense_3_accuracy: 0.6337 - val_loss: 2.0093 - val_dense_4_loss: 0.6778 - val_dense_1_loss: 0.6611 - val_dense_3_loss: 0.6705 - val_dense_4_accuracy: 0.6328 - val_dense_1_accuracy: 0.6328 - val_dense_3_accuracy: 0.6328\n",
            "Epoch 18/25\n",
            "32/32 [==============================] - 14s 451ms/step - loss: 2.0051 - dense_4_loss: 0.6686 - dense_1_loss: 0.6642 - dense_3_loss: 0.6722 - dense_4_accuracy: 0.6100 - dense_1_accuracy: 0.6081 - dense_3_accuracy: 0.6004 - val_loss: 1.9370 - val_dense_4_loss: 0.6480 - val_dense_1_loss: 0.6439 - val_dense_3_loss: 0.6451 - val_dense_4_accuracy: 0.6562 - val_dense_1_accuracy: 0.6562 - val_dense_3_accuracy: 0.6562\n",
            "Epoch 19/25\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 2.0378 - dense_4_loss: 0.6780 - dense_1_loss: 0.6736 - dense_3_loss: 0.6863 - dense_4_accuracy: 0.6024 - dense_1_accuracy: 0.6049 - dense_3_accuracy: 0.5880 - val_loss: 1.9557 - val_dense_4_loss: 0.6522 - val_dense_1_loss: 0.6502 - val_dense_3_loss: 0.6533 - val_dense_4_accuracy: 0.6445 - val_dense_1_accuracy: 0.6445 - val_dense_3_accuracy: 0.6445\n",
            "Epoch 20/25\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 2.0018 - dense_4_loss: 0.6677 - dense_1_loss: 0.6617 - dense_3_loss: 0.6723 - dense_4_accuracy: 0.6225 - dense_1_accuracy: 0.6245 - dense_3_accuracy: 0.6180 - val_loss: 1.9274 - val_dense_4_loss: 0.6435 - val_dense_1_loss: 0.6406 - val_dense_3_loss: 0.6434 - val_dense_4_accuracy: 0.6562 - val_dense_1_accuracy: 0.6562 - val_dense_3_accuracy: 0.6562\n",
            "Epoch 21/25\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.9121 - dense_4_loss: 0.6406 - dense_1_loss: 0.6371 - dense_3_loss: 0.6344 - dense_4_accuracy: 0.6700 - dense_1_accuracy: 0.6696 - dense_3_accuracy: 0.6671 - val_loss: 1.9531 - val_dense_4_loss: 0.6510 - val_dense_1_loss: 0.6510 - val_dense_3_loss: 0.6511 - val_dense_4_accuracy: 0.6445 - val_dense_1_accuracy: 0.6445 - val_dense_3_accuracy: 0.6445\n",
            "Epoch 22/25\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 2.0047 - dense_4_loss: 0.6662 - dense_1_loss: 0.6699 - dense_3_loss: 0.6686 - dense_4_accuracy: 0.6243 - dense_1_accuracy: 0.6276 - dense_3_accuracy: 0.6197 - val_loss: 1.9878 - val_dense_4_loss: 0.6705 - val_dense_1_loss: 0.6610 - val_dense_3_loss: 0.6564 - val_dense_4_accuracy: 0.6602 - val_dense_1_accuracy: 0.6602 - val_dense_3_accuracy: 0.6602\n",
            "Epoch 23/25\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 1.9549 - dense_4_loss: 0.6527 - dense_1_loss: 0.6486 - dense_3_loss: 0.6535 - dense_4_accuracy: 0.6707 - dense_1_accuracy: 0.6468 - dense_3_accuracy: 0.6639 - val_loss: 1.9590 - val_dense_4_loss: 0.6561 - val_dense_1_loss: 0.6484 - val_dense_3_loss: 0.6545 - val_dense_4_accuracy: 0.6484 - val_dense_1_accuracy: 0.6484 - val_dense_3_accuracy: 0.6484\n",
            "Epoch 24/25\n",
            "32/32 [==============================] - 14s 423ms/step - loss: 1.9937 - dense_4_loss: 0.6624 - dense_1_loss: 0.6631 - dense_3_loss: 0.6682 - dense_4_accuracy: 0.6234 - dense_1_accuracy: 0.6245 - dense_3_accuracy: 0.6225 - val_loss: 1.9330 - val_dense_4_loss: 0.6444 - val_dense_1_loss: 0.6382 - val_dense_3_loss: 0.6504 - val_dense_4_accuracy: 0.6602 - val_dense_1_accuracy: 0.6602 - val_dense_3_accuracy: 0.6602\n",
            "Epoch 25/25\n",
            "32/32 [==============================] - 14s 438ms/step - loss: 1.9647 - dense_4_loss: 0.6529 - dense_1_loss: 0.6543 - dense_3_loss: 0.6576 - dense_4_accuracy: 0.6517 - dense_1_accuracy: 0.6522 - dense_3_accuracy: 0.6516 - val_loss: 2.0290 - val_dense_4_loss: 0.6814 - val_dense_1_loss: 0.6714 - val_dense_3_loss: 0.6762 - val_dense_4_accuracy: 0.6133 - val_dense_1_accuracy: 0.6133 - val_dense_3_accuracy: 0.6133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdK0ubgRRtVd"
      },
      "source": [
        "#####**Inference**\n",
        "  The model is overfitting since the loss decreases and the accuracy increases initially, and then after couple of epochs the loss descreases but the accuracy also decreases. \n",
        "  \n",
        "  The accuracy is between 60 - 65% for the epochs between 25 to 30. For the model to learn properly, the epoch of 300 -400 is required by which the model is trained, and can reach the accuracy of >70%. Additionally, the batch size has to be increased say to 100. The batch size determines how many input images are fired into the architecture at a time. \n",
        "  \n",
        "  Eventhough the GoogLeNet architecture uses one of the regularization methods know as Dropout in the architecture but the training is overfitting in this case. \n",
        "  \n",
        "  To avoid overfitting of the GoogLeNet architecture, the four changes are implemented in the following sections:\n",
        "\n",
        "  **Change 1**: The model tends not to overfit if the training data is added more. Would try to add more training images, but due to time constraint only 30,000+ images were collected. To overcome this weights from the ImageNet dataset is used to train the GoogLeNet architecture.\n",
        "\n",
        "  **Change 2**: The accuracy and the loss in the model tends to fluctuate. This is due to the learning rate, which is not controlled properly. So in the GoogLeNet architecuture with the transfer learning , RMSprop with learning rate=0.001 is used(i.e. slow learning rate is used) instead of Adam optimizers.\n",
        "\n",
        "  **Change 3**: L2 regularization in the dense layer is used. The L2 regularization penalty is computed as: \n",
        "  \n",
        "           loss = l2 * reduce_sum(square(x))\n",
        "\n",
        "  **Change 4**: By default in the GoogLeNet architecture, in the output layer softmax function is used to do classification. But in this project, the binary classifications is perfomed. So in the following architecture, the sigmoid function is used.  \n",
        "       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aTxt25gxNPD"
      },
      "source": [
        "###**3.2: Transfer Learning with GoogLeNet Architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2fPJVMMxbIX"
      },
      "source": [
        "####**3.2.1 Creating Transfer Learning Architecture using GoogLenet Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1OcTw2QtCdN",
        "outputId": "010afa9c-050f-4ae2-dbc2-cab71337298b"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "#Transfer Learning with latest GoogleNet Architecture is used(Change 1)\n",
        "\n",
        "model.add(InceptionV3(include_top = False, weights=\"imagenet\", input_shape=(224, 224, 3))) \n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "\n",
        "# L2 regularizer(Change 3) and Sigmoid function is used(Change 4)\n",
        "\n",
        "model.add(Dense(1, activation = 'sigmoid',kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNb9vA_Ex-BO"
      },
      "source": [
        "####**3.2.2 Model Compilation/Execution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8usiAemNtacG"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "               optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['accuracy', tf.keras.metrics.AUC()]) # RMSprop with slower learning rate - Change 2"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvwc0nTnyVud"
      },
      "source": [
        "####**3.2.3 Fitting the model**\n",
        "\n",
        "  By implementing all the above 4 changes, the model training is performed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X6x0kA-t1a1",
        "outputId": "346772ce-3a03-4c14-86dc-3daaec6afe79"
      },
      "source": [
        "Google_fit_with_tl = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=32,  \n",
        "      epochs=25,\n",
        "      verbose=1,\n",
        "      validation_data = test_generator,\n",
        "      validation_steps=16)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "32/32 [==============================] - 20s 479ms/step - loss: 0.8172 - accuracy: 0.5739 - auc: 0.4836 - val_loss: 0.6593 - val_accuracy: 0.6641 - val_auc: 0.5708\n",
            "Epoch 2/25\n",
            "32/32 [==============================] - 14s 436ms/step - loss: 0.7134 - accuracy: 0.5864 - auc: 0.5621 - val_loss: 0.6688 - val_accuracy: 0.6016 - val_auc: 0.6184\n",
            "Epoch 3/25\n",
            "32/32 [==============================] - 14s 439ms/step - loss: 0.6911 - accuracy: 0.6054 - auc: 0.6159 - val_loss: 0.6111 - val_accuracy: 0.6602 - val_auc: 0.6883\n",
            "Epoch 4/25\n",
            "32/32 [==============================] - 14s 431ms/step - loss: 0.6585 - accuracy: 0.6326 - auc: 0.6361 - val_loss: 0.6445 - val_accuracy: 0.6445 - val_auc: 0.6215\n",
            "Epoch 5/25\n",
            "32/32 [==============================] - 14s 444ms/step - loss: 0.7162 - accuracy: 0.6079 - auc: 0.5800 - val_loss: 0.6514 - val_accuracy: 0.6836 - val_auc: 0.6363\n",
            "Epoch 6/25\n",
            "32/32 [==============================] - 14s 442ms/step - loss: 0.6626 - accuracy: 0.6314 - auc: 0.6280 - val_loss: 0.7312 - val_accuracy: 0.5352 - val_auc: 0.6120\n",
            "Epoch 7/25\n",
            "32/32 [==============================] - 14s 433ms/step - loss: 0.6723 - accuracy: 0.6274 - auc: 0.6453 - val_loss: 0.6736 - val_accuracy: 0.6211 - val_auc: 0.6829\n",
            "Epoch 8/25\n",
            "32/32 [==============================] - 14s 437ms/step - loss: 0.6598 - accuracy: 0.6470 - auc: 0.6299 - val_loss: 0.6688 - val_accuracy: 0.6055 - val_auc: 0.6841\n",
            "Epoch 9/25\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.6631 - accuracy: 0.6290 - auc: 0.6405 - val_loss: 0.6477 - val_accuracy: 0.6406 - val_auc: 0.6428\n",
            "Epoch 10/25\n",
            "32/32 [==============================] - 14s 436ms/step - loss: 0.6490 - accuracy: 0.6527 - auc: 0.6773 - val_loss: 0.6370 - val_accuracy: 0.6289 - val_auc: 0.7151\n",
            "Epoch 11/25\n",
            "32/32 [==============================] - 14s 432ms/step - loss: 0.6502 - accuracy: 0.6631 - auc: 0.6672 - val_loss: 0.6696 - val_accuracy: 0.6602 - val_auc: 0.6410\n",
            "Epoch 12/25\n",
            "32/32 [==============================] - 14s 431ms/step - loss: 0.6293 - accuracy: 0.6633 - auc: 0.6913 - val_loss: 0.7090 - val_accuracy: 0.5820 - val_auc: 0.6553\n",
            "Epoch 13/25\n",
            "32/32 [==============================] - 14s 435ms/step - loss: 0.6466 - accuracy: 0.6629 - auc: 0.6735 - val_loss: 0.6293 - val_accuracy: 0.6836 - val_auc: 0.6980\n",
            "Epoch 14/25\n",
            "32/32 [==============================] - 14s 435ms/step - loss: 0.6501 - accuracy: 0.6542 - auc: 0.6734 - val_loss: 0.6754 - val_accuracy: 0.6250 - val_auc: 0.6509\n",
            "Epoch 15/25\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 0.6701 - accuracy: 0.6493 - auc: 0.6672 - val_loss: 0.6230 - val_accuracy: 0.6602 - val_auc: 0.6894\n",
            "Epoch 16/25\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 0.6306 - accuracy: 0.6630 - auc: 0.6808 - val_loss: 0.5839 - val_accuracy: 0.7109 - val_auc: 0.7050\n",
            "Epoch 17/25\n",
            "32/32 [==============================] - 14s 432ms/step - loss: 0.6376 - accuracy: 0.6609 - auc: 0.6852 - val_loss: 0.6419 - val_accuracy: 0.6680 - val_auc: 0.7359\n",
            "Epoch 18/25\n",
            "32/32 [==============================] - 14s 437ms/step - loss: 0.6376 - accuracy: 0.6596 - auc: 0.6875 - val_loss: 0.6850 - val_accuracy: 0.6562 - val_auc: 0.7374\n",
            "Epoch 19/25\n",
            "32/32 [==============================] - 14s 433ms/step - loss: 0.6260 - accuracy: 0.6827 - auc: 0.6805 - val_loss: 0.6553 - val_accuracy: 0.6602 - val_auc: 0.6708\n",
            "Epoch 20/25\n",
            "32/32 [==============================] - 14s 431ms/step - loss: 0.6099 - accuracy: 0.6808 - auc: 0.7198 - val_loss: 0.7561 - val_accuracy: 0.6719 - val_auc: 0.6860\n",
            "Epoch 21/25\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 0.6749 - accuracy: 0.6410 - auc: 0.6684 - val_loss: 0.6859 - val_accuracy: 0.6445 - val_auc: 0.6812\n",
            "Epoch 22/25\n",
            "32/32 [==============================] - 13s 423ms/step - loss: 0.6273 - accuracy: 0.6778 - auc: 0.7126 - val_loss: 0.5982 - val_accuracy: 0.6953 - val_auc: 0.7031\n",
            "Epoch 23/25\n",
            "32/32 [==============================] - 14s 435ms/step - loss: 0.6352 - accuracy: 0.6653 - auc: 0.6910 - val_loss: 0.6484 - val_accuracy: 0.6641 - val_auc: 0.6598\n",
            "Epoch 24/25\n",
            "32/32 [==============================] - 13s 424ms/step - loss: 0.6176 - accuracy: 0.6810 - auc: 0.7101 - val_loss: 0.6310 - val_accuracy: 0.6523 - val_auc: 0.7229\n",
            "Epoch 25/25\n",
            "32/32 [==============================] - 14s 426ms/step - loss: 0.6336 - accuracy: 0.6856 - auc: 0.6978 - val_loss: 0.6280 - val_accuracy: 0.6602 - val_auc: 0.7226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F5mV8WCAC1E"
      },
      "source": [
        "###**4. Image Classification and Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOlDqL4_e-68",
        "outputId": "68ee5ad3-3176-41c7-9986-118078ed9e67"
      },
      "source": [
        "model.evaluate(test_generator) # Performance of the model on the test data"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "386/386 [==============================] - 66s 170ms/step - loss: 0.5994 - accuracy: 0.6875 - auc: 0.7234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5994104743003845, 0.6874898672103882, 0.7233552932739258]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsrFwG-WnVWB"
      },
      "source": [
        "####**Inference**\n",
        "\n",
        "The accuracy is slightly increased from 65% to 68.5% after making the four changes. The AUC is also increased from 0.51 to 0.72 which is acceptable in most cases. The accuracy is increased if the epochs are increased to the range 300-400."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcM8E_86kbhV",
        "outputId": "b1fbf2bd-6572-4275-b642-5ac3d1465b89"
      },
      "source": [
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "test_generator.reset()\n",
        "preds = model.predict(test_generator, \n",
        "                      verbose=1) # Prediction"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "386/386 [==============================] - 62s 159ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1GoYesqzEn-"
      },
      "source": [
        "###**5. Metrics Calculation**\n",
        "\n",
        "Now, calculating the ROC curve and plot it.\n",
        "\n",
        "First, let's make predictions on our test set. When using generators to make predictions, we must first turn off shuffle (as we did when we created validation_generator) and reset the generator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xadxc75p4bM"
      },
      "source": [
        "fpr, tpr, threshold = metrics.roc_curve(test_generator.classes, preds )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1SisekagYou"
      },
      "source": [
        "roc_auc = metrics.auc(fpr, tpr)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "SrC7IxqAgfl8",
        "outputId": "d81835b8-c9ac-49d8-970a-eb5704b4deb4"
      },
      "source": [
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic of the GoogleNet architecture without Transfer Learning')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb5fe1d8b01y"
      },
      "source": [
        "##**Conclusion**\n",
        "\n",
        "Even after performing all the four changes, the accuracy and the performance of the model is not upto the expectation. This may be due to 2 reasons. \n",
        "\n",
        "1. Labelling the train and test data was not done properly.\n",
        "2. Using less amount of data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtY6ByNjc95G"
      },
      "source": [
        "##**Future Work**\n",
        "\n",
        "1. Use other CNN lightweight architecture - MobileNet architecture with Transfer Learning, which is implemented in the other part of this coursework.\n",
        "2. Label the data and add more data, to increase the accuracy and performance.\n",
        "3. Use this architecture to create a Website and a MobileApp for common public use, and hence predict the Keto items."
      ]
    }
  ]
}