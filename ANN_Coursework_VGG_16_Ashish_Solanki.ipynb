{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN Coursework - Ashish Solanki.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajaramkuberan/ANN_Coursework_Coventry_Univ/blob/main/ANN_Coursework_VGG_16_Ashish_Solanki.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3ulAX65GNhJ"
      },
      "source": [
        "# **ANN Coursework**\n",
        "\n",
        "#### Ashish Solanki\n",
        "\n",
        "Here, we will train a VGG-16 NN to perform image classification on Ketogenic and Non-Ketogenic Food items, using transfer learning. Transfer learning means we will use. We will be using TensorFlow/Keras to build our neural network and training/test dataset. First, let's download the training and test data:\n",
        "we have provided dada in github for public use. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHC0Gwzix0cd",
        "outputId": "464747a9-e12e-4c67-846b-cd372ef20ad3"
      },
      "source": [
        "!git clone https://github.com/rajaramkuberan/ANN_Coursework_Coventry_Univ.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ANN_Coursework_Coventry_Univ'...\n",
            "remote: Enumerating objects: 4697, done.\u001b[K\n",
            "remote: Counting objects: 100% (4697/4697), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4689/4689), done.\u001b[K\n",
            "remote: Total 30301 (delta 8), reused 4697 (delta 8), pack-reused 25604\u001b[K\n",
            "Receiving objects: 100% (30301/30301), 6.11 GiB | 27.01 MiB/s, done.\n",
            "Resolving deltas: 100% (305/305), done.\n",
            "Checking out files: 100% (31400/31400), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVR3Z15Mx9_l"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.layers import concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8IW8WLwGesK"
      },
      "source": [
        "#### **Data Preprocessing**\n",
        "\n",
        "Now ,let's use ImageDataGenerator class to create our train and test dataset and normalize our data. \n",
        "\n",
        "It's important to normalize our data because data going into our CNN to improve its overall performance. We will use the rescale parameter to scale our image pixel values from [0, 255] to [0,1].\n",
        "\n",
        "In each generator, we specify the source directory of our images, the classes, the input image size, the batch size (how many images to process at once), and class mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHhRHswk9H0g"
      },
      "source": [
        "# initialising the image size as 224x224\n",
        "IMAGE_SIZE = [224,224]\n",
        "\n",
        "\n",
        "# Setting the Path to test and train data \n",
        "test_path = '/content/ANN_Coursework_Coventry_Univ/test'\n",
        "train_path = '/content/ANN_Coursework_Coventry_Univ/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8yrdHXv9Kl9"
      },
      "source": [
        "# transforming train data images\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "# transforming train data images\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkdXKYoZ9MPu",
        "outputId": "996c8d59-63c0-4f12-f4a8-a6b55b775b26"
      },
      "source": [
        "#training data \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/ANN_Coursework_Coventry_Univ/train',  # This is the source directory for training images\n",
        "        classes = ['Keto_train', 'Non_Keto_train'],\n",
        "        target_size=(224, 224),  # All images will be resized to 224x224\n",
        "        batch_size=32,\n",
        "        # Use binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# testing data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/ANN_Coursework_Coventry_Univ/test',  # This is the source directory for training images\n",
        "        classes = ['Keto_test', 'Non_Keto_Test'],\n",
        "        target_size=(224, 224),  # All images will be resized to 224x224\n",
        "        batch_size=16,\n",
        "        # Use binary labels\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24861 images belonging to 2 classes.\n",
            "Found 6163 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1YRe2ToGqbe"
      },
      "source": [
        "# **Building the Model**\n",
        "\n",
        "But before we continue, let's start defining the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMP1F8mt9UlL"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=2, activation=\"softmax\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_DzX3CnH7g-"
      },
      "source": [
        "The model.summary() method call prints a summary of the NN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RzwYwQuH5NO"
      },
      "source": [
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkQTEKjAH2sH"
      },
      "source": [
        "The \"output shape\" column shows the transformation of the dimensions of each layer as a result of the convolution and max pooling - convolution will reduce the layer size by a bit due to padding, and max pooling will halve the output size.\n",
        "\n",
        "\n",
        "Next, we'll configure the specifications for model training. We will train our model with the binary_crossentropy loss. We will use the Adam optimizer with a learning rate of 0.001. Adam is a sensible optimization algorithm because it automates learning-rate tuning for us (alternatively, we could also use Rms and Adagrad for similar results). We will add accuracy to metrics so that the model will monitor accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C37LkKCPHeVp"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "\n",
        "model.compile(optimizer='Adam', loss = 'sparse_categorical_crossentropy', metrics = 'accuracy', )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg8i-O65Jro4"
      },
      "source": [
        "### **Training**\n",
        "Let's train for 15 epochs -- this may take a few minutes to run.\n",
        "\n",
        "Note that steps_per_epoch was set along with batch_size in ImageDataGenerator.\n",
        "\n",
        "Notice that as we train, our test accuracy never exceeds training accuracy, which is a good thing. Our model won't work better on unseen images than seen images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH2ZgamBJlDl"
      },
      "source": [
        "# epochs is 30  \n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=1,  \n",
        "      epochs=2,\n",
        "      verbose=1,\n",
        "      validation_data = test_generator,\n",
        "      validation_steps=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBTKUXscJ6MU"
      },
      "source": [
        "# Accuracy, ROC Curve, and AUC\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsQPTU2BJk-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e151c38a-2945-4ab5-b932-c321efd46c04"
      },
      "source": [
        "model.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "386/386 [==============================] - 70s 181ms/step - loss: 0.6543 - accuracy: 0.6393\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6542653441429138, 0.6392990350723267]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf2rtN90Jk5S"
      },
      "source": [
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "test_generator.reset()\n",
        "preds = model.predict(test_generator,\n",
        "                      verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR7B7FgCJkzJ"
      },
      "source": [
        "fpr, tpr, _ = roc_curve(test_generator.classes, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZyM0o_JKAt4"
      },
      "source": [
        "roc_auc = auc(fpr, tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N88vaESQKCi_"
      },
      "source": [
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9nxBXBeKCeU"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCQr64PFKCZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9accf774-8aec-4b60-c094-b9b26cb656c2"
      },
      "source": [
        "hist = model.fit_generator(steps_per_epoch=10,generator=train_generator, validation_data= test_generator, validation_steps=10,epochs=10,callbacks=[checkpoint,early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 7s 668ms/step - loss: 0.6639 - accuracy: 0.6250 - val_loss: 0.6583 - val_accuracy: 0.6313\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 7s 656ms/step - loss: 0.6677 - accuracy: 0.6125 - val_loss: 0.6704 - val_accuracy: 0.6062\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 6s 642ms/step - loss: 0.6454 - accuracy: 0.6625 - val_loss: 0.6585 - val_accuracy: 0.6313\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 7s 658ms/step - loss: 0.6531 - accuracy: 0.6406 - val_loss: 0.6702 - val_accuracy: 0.6125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 7s 677ms/step - loss: 0.6618 - accuracy: 0.6281 - val_loss: 0.6662 - val_accuracy: 0.6187\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 6s 640ms/step - loss: 0.6714 - accuracy: 0.6062 - val_loss: 0.6647 - val_accuracy: 0.6187\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 7s 648ms/step - loss: 0.6390 - accuracy: 0.6719 - val_loss: 0.6519 - val_accuracy: 0.6438\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 7s 657ms/step - loss: 0.6679 - accuracy: 0.6156 - val_loss: 0.6760 - val_accuracy: 0.6000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 7s 657ms/step - loss: 0.6624 - accuracy: 0.6281 - val_loss: 0.6561 - val_accuracy: 0.6375\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 7s 648ms/step - loss: 0.6578 - accuracy: 0.6344 - val_loss: 0.6953 - val_accuracy: 0.5625\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi14DPxJKCVk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history[\"acc\"])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95_RidC5L0Ij"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "img = image.load_img(\"/content/1.jpg\",target_size=(224,224))\n",
        "img = np.asarray(img)\n",
        "plt.imshow(img)\n",
        "img = np.expand_dims(img, axis=0)\n",
        "from keras.models import load_model\n",
        "saved_model = load_model(\"vgg16_1.h5\")\n",
        "output = saved_model.predict(img)\n",
        "if output[0][0] > output[0][1]:\n",
        "    print(\"keto\")\n",
        "else:\n",
        "    print('non-keto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyGxHWlRaA00"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}